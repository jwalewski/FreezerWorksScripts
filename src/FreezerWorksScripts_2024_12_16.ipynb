{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de806492-0b13-4f5c-9ea2-40811e8dbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part zero: import packages\n",
    "import numpy\n",
    "import pandas\n",
    "import re\n",
    "import math #was requested to use math to floor aliquot numbers\n",
    "from typing import Union\n",
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)  # Clear existing handlers\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING, stream=sys.stdout)\n",
    "\n",
    "def main():\n",
    "    input_filepath=\"../data/input/\"\n",
    "    input_filename=\"22-535 sample tracking.csv\"#\n",
    "    import_style=\"DF\" # Other implemented options are \"SF\" and \"Fw_import\"\n",
    "    export_style=\"Sample_map\" #Implemented options are \"Fw_import\" and \"Sample_map\"\n",
    "    output_filepath=\"../data/exports/\"\n",
    "    output_filename=f\"TEST_{export_style}.csv\" #Can be left blank as well\n",
    "    row_offset=1 #Determines which row will be the column names of the pandas dataframe\n",
    "    intermediate_dataframe=read_file(input_dataframe_filepath=input_filepath, input_data_filename=input_filename, import_style=import_style, row_offset=row_offset) #The return type is called intermediate_dataframe because another dataframe is created in .write() that is actually exported \n",
    "    export_dataframe(input_dataframe=intermediate_dataframe, output_filepath=output_filepath+output_filename, output_filename=output_filename, style=export_style)\n",
    "\n",
    "def read_file(input_dataframe_filepath: str, input_data_filename:str, import_style:str, row_offset:Union[int, None]=None) -> pandas.DataFrame: #alternate datatypes could be pandas dataframes, both for the lists and each element\n",
    "    \"\"\"Reads in a csv file from varying sources (dependent on \"style\") and returns a pandas dataframe in a freezerworks-like format, minus the headers\"\"\"\n",
    "    #We start each instance by reading in a file\n",
    "    output_columns = [\n",
    "        \"(Neuro) Patient ID\", \"(HaflerLab) Substudy Visit\", \"(HaflerLab) Aliquot ID\", \n",
    "        \"(HaflerLab) Sample ID\", \"YCCI_Sample Type\", \"Sample Additive\", \n",
    "        \"Aliquot Type\", \"Sample Collection Date\", \"Aliquot Additive\", \n",
    "        \"Current Amount\", \"Aliquot UOM\", \"Sample Volume\", \"Sample UOM\", \"Notes\"\n",
    "    ]\n",
    "    ONE_MILLION=1000000 #One million\n",
    "    output_dataframe = pandas.DataFrame(columns=output_columns)\n",
    "    if row_offset:\n",
    "        current_dataframe = pandas.read_csv(input_dataframe_filepath+input_data_filename, header=row_offset) #could hypothetically be moved inside the parameters for each site\n",
    "    else:\n",
    "        current_dataframe = pandas.read_csv(input_dataframe_filepath+input_data_filename)\n",
    "    if import_style==\"DF\":\n",
    "        #make sure there are no completely empty rows\n",
    "        #Now, parse information for the new Freezerworks style dataframe\n",
    "        for idx, row in current_dataframe.iterrows(): \n",
    "            #Could one day even add an if statement up here for tumor samples if I deem it necessary\n",
    "            if row.isnull().all() :\n",
    "                continue #skip this row\n",
    "            logging.debug(f\"this loop runs, and we are on row \\n {row} and index {idx}\\n\")\n",
    "            output_row = pandas.Series()  # Temporary dictionary to store the transformed row\n",
    "            # Populate each field according to the transformation logic\n",
    "\n",
    "            # (Neuro) Patient ID\n",
    "            if not pandas.isna(row[\"Patient ID (SitePatient Number_B_Timepoint)\"]):\n",
    "                neuro_patient_id = row[\"Patient ID (SitePatient Number_B_Timepoint)\"][:2] + row[\"Patient ID (SitePatient Number_B_Timepoint)\"][4:6] #extracts DF and ##, and then adds them\n",
    "                output_row[\"(Neuro) Patient ID\"] = neuro_patient_id\n",
    "            else:\n",
    "                logging.warning(f\"Warning: value {row['Patient ID (SitePatient Number_B_Timepoint)']} detected in row {row}\\n\")\n",
    "            \n",
    "            # (HaflerLab) Substudy Visit\n",
    "            row_value = row[\"Patient ID (SitePatient Number_B_Timepoint)\"]\n",
    "            if type(row_value) == str:\n",
    "                visit_day=row_value[9:]\n",
    "                if \"EOT\" in visit_day: #Highest priority\n",
    "                    visit_day = \"EOT\"\n",
    "                elif \"SURG\" in visit_day: #replace with OR\n",
    "                    visit_day = \"OR\"\n",
    "                elif visit_day[0]==\"C\": #replace with V... and remove D# part\n",
    "                    visit_day = visit_day[:-2] #take everything but last two chars (which are always D1)\n",
    "                    if len(visit_day)==2:\n",
    "                        visit_day = \"V0\"+visit_day[1:]\n",
    "                    else:\n",
    "                        visit_day = \"V\"+visit_day[1:]\n",
    "            output_row[\"(HaflerLab) Substudy Visit\"] = visit_day\n",
    "                \n",
    "            #Also, there is no condition for PRE patients, because the syntax they already use is what we use\n",
    "            #print(visit_day)\n",
    "            #get everything after the second underscore\n",
    "    \n",
    "        \n",
    "            # (HaflerLab) Aliquot ID (placeholder)\n",
    "            output_row[\"(HaflerLab) Aliquot ID\"] = None  # Modify with actual logic as needed\n",
    "            \n",
    "            # (HaflerLab) Sample ID (placeholder)\n",
    "            output_row[\"(HaflerLab) Sample ID\"] = None  # Modify with actual logic as needed\n",
    "            #line from script iteration\n",
    "            #haflerlab_sample_id= ''.join(str(num) for num in [ord(char) for char in (neuro_patient_id+haflerlab_substudy_visit+ycci_sample_type+sample_volume)])+\",\" #creates a unique sample ID based on the concatenation of patient ID, substudy visit, sample type, and sample volume\n",
    "    \n",
    "            # YCCI_Sample Type\n",
    "            output_row[\"YCCI_Sample Type\"] = \"Blood\"\n",
    "            \n",
    "            # Sample Collection Date\n",
    "            output_row[\"Sample Collection Date\"] = row[\"Date\"]\n",
    "            \n",
    "            # Sample UOM\n",
    "            output_row[\"Sample UOM\"] = \"mL\"\n",
    "            \n",
    "            # Notes\n",
    "            output_row[\"Notes\"] = \"Computer Generated Entry\"\n",
    "        \n",
    "            #Update Sample ID based off ASCII information \n",
    "            #output_row[\"(HaflerLab) Sample ID\"]=''.join(str(num) for num in [ord(char) for char in (output_row[\"(Neuro) Patient ID\"]+output_row[\"(HaflerLab) Substudy Visit\"]+output_row[\"YCCI_Sample Type\"]+str(output_row[\"Sample Volume\"]))]) #suffixes a number after the sample ID for the aliqout ID\n",
    "    \n",
    "            #For Serum Aliquots\n",
    "            #temporarily assign sample volume to 6 and aliwuot type to Serum for Serum, then 25 and PBMC for PBMC after serum for loop is done\n",
    "            output_row[\"Sample Volume\"] = 6 #Sample UOM can be filled out earlier as it is mL in both cases\n",
    "            output_row[\"Sample Additive\"] = \"No Additive\"\n",
    "            sample_id_string = (str(output_row[\"(Neuro) Patient ID\"])+str(output_row[\"(HaflerLab) Substudy Visit\"])+str(output_row[\"YCCI_Sample Type\"])+str(output_row[\"Sample Volume\"]))\n",
    "            output_row[\"(HaflerLab) Sample ID\"] = ''.join(str(num) for num in [ord(char) for char in sample_id_string])\n",
    "            #print(f\"Here is sample_id_string for Serum: {sample_id_string}\")\n",
    "            output_row[\"Aliquot Type\"] = \"Serum\"   \n",
    "            output_row[\"Aliquot Additive\"] = \"No Additive\"\n",
    "            output_row[\"Aliquot UOM\"] = \"mL\"\n",
    "            #output_row[\"(HaflerLab) Sample ID\"]=''.join(str(num) for num in [ord(char) for char in (output_row[\"(Neuro) Patient ID\"]+output_row[\"(HaflerLab) Substudy Visit\"]+output_row[\"YCCI_Sample Type\"]+str(output_row[\"Sample Volume\"]))]) #suffixes a number after the sample ID for the aliqout ID\n",
    "            number_of_serum_aliquots=row[\"Number of Serum Vials\"]\n",
    "            output_row = pandas.DataFrame(output_row) #These might work up here, otherwise they will have to move into the loops\n",
    "            output_row=output_row.transpose()\n",
    "            if not pandas.isna(number_of_serum_aliquots):\n",
    "                output_row[\"Current Amount\"] = .5\n",
    "                for i in range(int(number_of_serum_aliquots)): \n",
    "                    logging.debug(f' Sample_id_string is: {sample_id_string} and its type is: {type(sample_id_string)}\\nMeanwhile, output_row[\"(Neuro) Patient ID\"]) is: {output_row[\"(Neuro) Patient ID\"]}\\noutput_row[\"(HaflerLab) Substudy Visit\"] is: {output_row[\"(HaflerLab) Substudy Visit\"]}\\noutput_row[\"YCCI_Sample Type\"] is: {output_row[\"YCCI_Sample Type\"]}\\noutput_row[\"Sample Volume\"] is {output_row[\"Sample Volume\"]}')\n",
    "                    output_row[\"(HaflerLab) Aliquot ID\"] = ''.join(str(num) for num in [ord(char) for char in sample_id_string])+\".\"+str(i)#suffixes a number after the sample ID for the aliqout ID\n",
    "                    logging.debug(f'We are outputting aliquot number {i} with sample ID {output_row[\"(HaflerLab) Sample ID\"]} and aliquot id {output_row[\"(HaflerLab) Aliquot ID\"]}')\n",
    "                    output_dataframe = pandas.concat([output_dataframe, output_row])\n",
    "            \n",
    "            #For PBMC Aliquots\n",
    "            output_row[\"Sample Volume\"] = 25  #Sample UOM can be filled out earlier as it is mL in both cases\n",
    "            output_row[\"Sample Additive\"] = \"Lithium Heparin\"\n",
    "            output_row[\"Aliquot Type\"] = \"PBMC\"\n",
    "            output_row[\"Aliquot Additive\"] = \"DMSO\"\n",
    "            output_row[\"Aliquot UOM\"] = \"million\"\n",
    "            #output_row[\"(HaflerLab) Sample ID\"]=''.join(str(num) for num in [ord(char) for char in (output_row[\"(Neuro) Patient ID\"]+output_row[\"(HaflerLab) Substudy Visit\"]+output_row[\"YCCI_Sample Type\"]+str(output_row[\"Sample Volume\"]))]) #suffixes a number after the sample ID for the aliqout ID\n",
    "            sample_id_string = (str(output_row[\"(Neuro) Patient ID\"].values[0])+str(output_row[\"(HaflerLab) Substudy Visit\"].values[0])+str(output_row[\"YCCI_Sample Type\"].values[0])+str(output_row[\"Sample Volume\"].values[0]))\n",
    "            logging.debug(f\"Here is sample_id_string for PBMCs: {sample_id_string}\")\n",
    "            output_row[\"(HaflerLab) Sample ID\"] = ''.join(str(num) for num in [ord(char) for char in sample_id_string])\n",
    "            number_of_pbmc_aliquots=row[\"Number of PBMCs Vials\"]\n",
    "            # Current Amount\n",
    "            logging.debug(f'This is {row[\"PBMC count (total cells/sample)\"]} and this is wether it is pandas.isna(): {pandas.isna(row[\"PBMC count (total cells/sample)\"])} and whether it is numpy.isnan(): {numpy.isnan(row[\"PBMC count (total cells/sample)\"])}')\n",
    "            if (not pandas.isna(number_of_pbmc_aliquots)) and (not pandas.isna(row[\"PBMC count (total cells/sample)\"])):\n",
    "                output_row[\"Current Amount\"] = math.floor(int(row[\"PBMC count (total cells/sample)\"]) / int(number_of_pbmc_aliquots)/ONE_MILLION) #if not pandas.isna(row[\"PBMC count (total cells/sample)\"]) else print(f\"Warning: NA value {row[\"PBMC count (total cells/sample)\"]} in row {row}\")\n",
    "                for i in range(int(number_of_pbmc_aliquots)):\n",
    "                    id_string = (str(output_row[\"(Neuro) Patient ID\"].values[0])+str(output_row[\"(HaflerLab) Substudy Visit\"].values[0])+str(output_row[\"YCCI_Sample Type\"].values[0])+str(output_row[\"Sample Volume\"].values[0]))\n",
    "                    #output_row[\"(HaflerLab) Aliquot ID\"] = ''.join(str(num) for num in [ord(char) for char in id_string])+\".\"+str(i)#suffixes a number after the sample ID for the aliqout ID\n",
    "                    logging.debug(f'id_string is: {id_string} and its type is: {type(id_string)}\\nMeanwhile, output_row[\"(Neuro) Patient ID\"]) is: {output_row[\"(Neuro) Patient ID\"]}\\noutput_row[\"(HaflerLab) Substudy Visit\"] is: {output_row[\"(HaflerLab) Substudy Visit\"]}\\noutput_row[\"YCCI_Sample Type\"] is: {output_row[\"YCCI_Sample Type\"]}\\noutput_row[\"Sample Volume\"] is {output_row[\"Sample Volume\"]}')\n",
    "                    output_row[\"(HaflerLab) Aliquot ID\"] = ''.join(str(num) for num in [ord(char) for char in sample_id_string])+\".\"+str(i)#suffixes a number after the sample ID for the aliqout ID\n",
    "                    logging.debug(f'We are outputting aliquot number {i} with sample ID {output_row[\"(HaflerLab) Sample ID\"]} and aliquot id {output_row[\"(HaflerLab) Aliquot ID\"]}')\n",
    "                    output_dataframe = pandas.concat([output_dataframe, output_row])\n",
    "\n",
    "        return output_dataframe \n",
    "    \n",
    "    if import_style == \"SF\":\n",
    "        #Remove rows with NA PBMC counts that represent the other PBMC samples via bitwise logic\n",
    "        current_dataframe = current_dataframe.loc[~((current_dataframe[\"Cell Count\"].isna()) & (current_dataframe[\"Sample Type\"] == \"PBMC\"))]\n",
    "        #do regex to convert scientific notation to python friendly version\n",
    "        #in theory, this could be done inside the loop for efficiency, but that will come later\n",
    "        current_dataframe[\"Cell Count\"] = current_dataframe[\"Cell Count\"].apply(lambda x: float(re.sub(r'.10\\^', 'e', str(x))) if (isinstance(x, str) and ('X10^' or 'x10' in x)) else x)\n",
    "        #Now, parse information for the new Freezerworks style dataframe\n",
    "        for idx, row in current_dataframe.iterrows():\n",
    "            #print(f\"this loop runs, and we are on row \\n {row} and index {idx}\\n\")\n",
    "            output_row = pandas.Series()  # Temporary dictionary to store the transformed row\n",
    "            # Populate each field according to the transformation logic\n",
    "            \n",
    "            # (Neuro) Patient ID\n",
    "            neuro_patient_id = \"SF\" + row[\"Sample ID\"][-2:] if isinstance(row[\"Sample ID\"], str) else None\n",
    "            output_row[\"(Neuro) Patient ID\"] = neuro_patient_id\n",
    "            \n",
    "            # (HaflerLab) Substudy Visit\n",
    "            visit_day = row.get(\"Visit Day\", \"\")\n",
    "            if \"C\" in visit_day:\n",
    "                number=re.search(\"[0-9]+\", visit_day)\n",
    "                number=str(number.group()) #extracts the actual # from number and converts it to a str\n",
    "                if len(number) ==1:\n",
    "                    output_row[\"(HaflerLab) Substudy Visit\"] = \"V0\" + visit_day[1]\n",
    "                else:\n",
    "                    output_row[\"(HaflerLab) Substudy Visit\"] = \"V\" + visit_day[1]\n",
    "                \n",
    "            elif \"PRE\" in visit_day: #will have to handle later; current manifest does not have this so I don't know that their syntax is\n",
    "                output_row[\"(HaflerLab) Substudy Visit\"] = visit_day\n",
    "            elif any(term in visit_day for term in [\"OR\", \"SURG\"]): #will have to handle later; current manifest does not have this so I don't know that their syntax is\n",
    "                output_row[\"(HaflerLab) Substudy Visit\"] = visit_day\n",
    "            elif \"Safety Follow Up\" in visit_day:\n",
    "                output_row[\"(HaflerLab) Substudy Visit\"] = \"FU01\" #stands for follow up. For now, we only have 01.\n",
    "            else:\n",
    "                raise Exception(f\"Invalid timepoint {visit_day} in Visit Day. Check CSV.\")\n",
    "        \n",
    "            # (HaflerLab) Aliquot ID (placeholder)\n",
    "            output_row[\"(HaflerLab) Aliquot ID\"] = None  # Modify with actual logic as needed\n",
    "            \n",
    "            # (HaflerLab) Sample ID (placeholder)\n",
    "            output_row[\"(HaflerLab) Sample ID\"] = None  # Modify with actual logic as needed\n",
    "            #line from script iteration\n",
    "            #haflerlab_sample_id= ''.join(str(num) for num in [ord(char) for char in (neuro_patient_id+haflerlab_substudy_visit+ycci_sample_type+sample_volume)])+\",\" #creates a unique sample ID based on the concatenation of patient ID, substudy visit, sample type, and sample volume\n",
    "\n",
    "            # YCCI_Sample Type\n",
    "            output_row[\"YCCI_Sample Type\"] = \"Blood\"\n",
    "        \n",
    "            # Sample Additive\n",
    "            output_row[\"Sample Additive\"] = \"Lithium Heparin\" if row[\"Sample Type\"] == \"PBMC\" else \"No Additive\"\n",
    "        \n",
    "            # Aliquot Type\n",
    "            output_row[\"Aliquot Type\"] = row[\"Sample Type\"]\n",
    "        \n",
    "            # Sample Collection Date\n",
    "            output_row[\"Sample Collection Date\"] = row[\"Sample Date\"]\n",
    "        \n",
    "            # Aliquot Additive\n",
    "            output_row[\"Aliquot Additive\"] = \"DMSO\" if row[\"Sample Type\"] == \"PBMC\" else \"No Additive\"\n",
    "        \n",
    "            # Current Amount\n",
    "            output_row[\"Current Amount\"] = math.floor(int(row[\"Cell Count\"]) / int(row[\"Number of Aliquots Total\"])/ONE_MILLION) if row[\"Sample Type\"] == \"PBMC\" else 0.5\n",
    "        \n",
    "            # Aliquot UOM\n",
    "            output_row[\"Aliquot UOM\"] = \"million\" if row[\"Sample Type\"] == \"PBMC\" else \"mL\"\n",
    "        \n",
    "            # Sample Volume\n",
    "            output_row[\"Sample Volume\"] = 25 if row[\"Sample Type\"] == \"PBMC\" else 6\n",
    "        \n",
    "            # Sample UOM\n",
    "            output_row[\"Sample UOM\"] = \"mL\"\n",
    "            \n",
    "            # Notes\n",
    "            output_row[\"Notes\"] = \"Computer Generated Entry\"\n",
    "        \n",
    "            #Update Sample ID based off ASCII information \n",
    "            output_row[\"(HaflerLab) Sample ID\"]=''.join(str(num) for num in [ord(char) for char in (output_row[\"(Neuro) Patient ID\"]+output_row[\"(HaflerLab) Substudy Visit\"]+output_row[\"YCCI_Sample Type\"]+str(output_row[\"Sample Volume\"]))]) #suffixes a number after the sample ID for the aliqout ID\n",
    "\n",
    "            #convert series to DataFrame\n",
    "            output_row=pandas.DataFrame(output_row)\n",
    "            output_row=output_row.transpose()\n",
    "        \n",
    "            logging.debug(f\"output row is: \\n{output_row}\\n\")\n",
    "            \n",
    "            # Append the transformed row to Freezerworks_CSVsframe depending on the number of aliqouts with this information\n",
    "            number_of_aliquots=row[\"Number of Aliquots Total\"]\n",
    "            for i in range(int(number_of_aliquots)):\n",
    "                id_string = (str(output_row[\"(Neuro) Patient ID\"].values[0])+str(output_row[\"(HaflerLab) Substudy Visit\"].values[0])+str(output_row[\"YCCI_Sample Type\"].values[0])+str(output_row[\"Sample Volume\"].values[0]))\n",
    "                logging.debug(f'id_string is: {id_string} and its type is: {type(id_string)}\\nMeanwhile, output_row[\"(Neuro) Patient ID\"]) is: {output_row[\"(Neuro) Patient ID\"]}\\noutput_row[\"(HaflerLab) Substudy Visit\"] is: {output_row[\"(HaflerLab) Substudy Visit\"]}\\noutput_row[\"YCCI_Sample Type\"] is: {output_row[\"YCCI_Sample Type\"]}\\noutput_row[\"Sample Volume\"] is {output_row[\"Sample Volume\"]}')\n",
    "                output_row[\"(HaflerLab) Aliquot ID\"] = ''.join(str(num) for num in [ord(char) for char in id_string])+\".\"+str(i)#suffixes a number after the sample ID for the aliqout ID\n",
    "                output_dataframe = pandas.concat([output_dataframe, output_row])\n",
    "\n",
    "        return output_dataframe\n",
    "\n",
    "\n",
    "\n",
    "    if import_style==\"FW_import\": #there is no YU style because we don't have a manifest for ourselves. Instead it's just the freezerworks exports, which could come from any site\n",
    "        #this one should be fairly easy because we're just re-importing the CSV\n",
    "        output_columns= [\n",
    "            \"(Neuro) Patient ID\", \"(HaflerLab) Substudy Visit\", \"(HaflerLab) Aliquot ID\", \n",
    "            \"(HaflerLab) Sample ID\", \"YCCI_Sample Type\", \"Sample Additive\", \n",
    "            \"Aliquot Type\", \"Sample Collection Date\", \"Aliquot Additive\", \n",
    "            \"Current Amount\", \"Aliquot UOM\", \"Sample Volume\", \"Sample UOM\", \"Notes\"\n",
    "        ] #required to assign unique column names to sort \n",
    "        #Note, technically ones exported straight from FW will have the headers still in and an empty row in the indexes, so they should have headers and indices of 0      \n",
    "        if(len(current_dataframe.columns) == len(output_columns)):\n",
    "            current_dataframe.columns = output_columns\n",
    "            return output_dataframe\n",
    "        else:\n",
    "            raise Exception(f\"The number of columns in the old dataframe ({len(current_dataframe.columns)}) does not match the number of columns that is expected of this style ({len(output_columns)}).\")    \n",
    " \n",
    "\n",
    "def export_dataframe(input_dataframe: pandas.DataFrame, style:str=\"Fw_import\", output_filepath:str=\"../data/exports/\", output_filename:str=None, row_offset: Union[None,int]=None, column_offset: Union[None,int]=None) -> None:\n",
    "    \"\"\"Expects a dataframe in FW-import sytle, minus any headers or indices. Can either write it to a CSV for import into FW, or can generate a sample map CSV for use in the Hafler Lab sample map format. \"\"\"\n",
    "    \n",
    "    if output_filename == None:\n",
    "        output_filename=f\"TEST_{style}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\" #.csv extension is appended later, once sample type is determined\n",
    "\n",
    "    if style == \"Fw_import\":\n",
    "        input_dataframe.to_csv(output_filepath, header=False, index=False) #To import into freezerworks the header and indices must be discarded\n",
    "        return\n",
    "    elif style == \"Sample_map\":\n",
    "        input_dataframe[\"Internal Date\"] = pandas.to_datetime(input_dataframe[\"Sample Collection Date\"], format='%m/%d/%y')\n",
    "        input_dataframe_sorted = input_dataframe.sort_values(by=[\"Internal Date\", \"(Neuro) Patient ID\"], ascending=[True, True])\n",
    "        serum_sample_map_dataframe=pandas.DataFrame()#(columns=\"Column 1\")\n",
    "        pbmc_sample_map_dataframe=pandas.DataFrame()\n",
    "        serum_aliquots = pandas.Series()\n",
    "        pbmc_aliquots = pandas.Series()\n",
    "        for index, row in input_dataframe_sorted.iterrows():\n",
    "            logging.debug(f\"row is: {row} and index is: {index}\")\n",
    "            #Extract Relevant information\n",
    "            #Patient ID\n",
    "            patient_id = row[\"(Neuro) Patient ID\"]\n",
    "            logging.debug(f\"This is patient_id: {patient_id}\")\n",
    "            #Timepoint\n",
    "            timepoint = row[\"(HaflerLab) Substudy Visit\"]\n",
    "            logging.debug(f\"This is timepoint: {timepoint}\")\n",
    "            #sample collection date\n",
    "            date = row[\"Sample Collection Date\"]\n",
    "            logging.debug(f\"This is date: {date}\")\n",
    "            #current amount\n",
    "            current_amount = str(row[\"Current Amount\"])\n",
    "            logging.debug(f\"This is current_amount: {current_amount}\")\n",
    "            #aliquot UOM\n",
    "            aliquot_uom = row[\"Aliquot UOM\"]\n",
    "            logging.debug(f\"This is aliquot_uom: {aliquot_uom}\")\n",
    "        \n",
    "            entry_string = patient_id+timepoint+\" \"+date+\" \"+current_amount+aliquot_uom  \n",
    "            logging.debug(f\"This is entry_string: {entry_string}\")\n",
    "        \n",
    "            \n",
    "            if row[\"Aliquot Type\"] == \"PBMC\":\n",
    "        \n",
    "                #add to PBMC Sample Series\n",
    "                new_series = pandas.Series(entry_string)\n",
    "                logging.debug(f\"new_series is: {new_series}\")\n",
    "                pbmc_aliquots = pandas.concat([pbmc_aliquots, new_series])\n",
    "                logging.debug(f\"pbmc_aliquots is: {pbmc_aliquots}\")\n",
    "                #turn row into dataframe and transpose\n",
    "                #then add to map\n",
    "                #then,\n",
    "                #maybe in here check to see if series length is 10, then write to dataframe, then reset?\n",
    "                if len(pbmc_aliquots) == 10:\n",
    "                    pbmc_aliquots = pandas.DataFrame(pbmc_aliquots)\n",
    "                    pbmc_aliquots = pbmc_aliquots.transpose()\n",
    "                    pbmc_sample_map_dataframe = pandas.concat([pbmc_sample_map_dataframe, pbmc_aliquots], ignore_index=True)\n",
    "                    logging.debug(f\"pbmc_sample_map_dataframe is: {pbmc_sample_map_dataframe}\")\n",
    "                    #now, reset pbmc_aliquots so it doesn't mess up the next version of the loop\n",
    "                    pbmc_aliquots = pandas.Series()\n",
    "            if row[\"Aliquot Type\"] == \"Serum\":\n",
    "        \n",
    "                #add to serum Sample Series\n",
    "                new_series = pandas.Series(entry_string)\n",
    "                logging.debug(f\"new_series is: {new_series}\")\n",
    "                serum_aliquots = pandas.concat([serum_aliquots, new_series])\n",
    "                logging.debug(f\"serum_aliquots is: {serum_aliquots}\")\n",
    "                #turn row into dataframe and transpose\n",
    "                #then add to map\n",
    "                #then,\n",
    "                #maybe in here check to see if series length is 10, then write to dataframe, then reset?\n",
    "                if len(serum_aliquots) == 10:\n",
    "                    serum_aliquots = pandas.DataFrame(serum_aliquots)\n",
    "                    serum_aliquots = serum_aliquots.transpose()\n",
    "                    serum_sample_map_dataframe = pandas.concat([serum_sample_map_dataframe, serum_aliquots], ignore_index=True) #indexing error that I will have to address later\n",
    "                    logging.debug(f\"serum_sample_map_dataframe is: {serum_sample_map_dataframe}\")\n",
    "                    #now, reset serum_aliquots so it doesn't mess up the next version of the loop\n",
    "                    serum_aliquots = pandas.Series()\n",
    "        \n",
    "\n",
    "        #Code to handle when the final row has less than 10 aliquots, in which case it will need padding with an empty string\n",
    "        serum_aliquot_length_difference = 10-len(serum_aliquots)\n",
    "        if serum_aliquot_length_difference > 0: #Checking if any difference exists\n",
    "            extra_spaces = pandas.Series([\" \"] * serum_aliquot_length_difference)\n",
    "            serum_aliquots = pandas.concat([serum_aliquots, extra_spaces], ignore_index=True)\n",
    "        serum_aliquots = pandas.DataFrame(serum_aliquots)\n",
    "        serum_aliquots = serum_aliquots.transpose()\n",
    "        serum_aliquots.columns=[0]*10 # Sets all column names to 0, which allows for concatenation with the rest of the sample map dataframe\n",
    "        serum_sample_map_dataframe = pandas.concat([serum_sample_map_dataframe, serum_aliquots], ignore_index=True) #this needs to run one more time after the loop is over so that the remaining samples are added\n",
    "\n",
    "        pbmc_aliquot_length_difference = 10-len(pbmc_aliquots)\n",
    "        if pbmc_aliquot_length_difference > 0: #Checking if any difference exists\n",
    "            extra_spaces = pandas.Series([\" \"] * pbmc_aliquot_length_difference)\n",
    "            pbmc_aliquots = pandas.concat([pbmc_aliquots, extra_spaces], ignore_index=True)\n",
    "        pbmc_aliquots = pandas.DataFrame(pbmc_aliquots)\n",
    "        pbmc_aliquots = pbmc_aliquots.transpose()\n",
    "        pbmc_aliquots.columns=[0]*10 # Sets all column names to 0, which allows for concatenation with the rest of the sample map dataframe\n",
    "        pbmc_sample_map_dataframe = pandas.concat([pbmc_sample_map_dataframe, pbmc_aliquots], ignore_index=True) #this needs to run one more time after the loop is over so that the remaining samples are added\n",
    "        \n",
    "        #writing to outputfile\n",
    "        output_filename+=\"_serum.csv\"\n",
    "        serum_sample_map_dataframe.to_csv(output_filepath+output_filename, header=False, index=False)\n",
    "        output_filename=output_filename[:-10] #remove last 10 chars, which was the previous ending\n",
    "        output_filename+=\"_pbmc.csv\"\n",
    "        pbmc_sample_map_dataframe.to_csv(output_filepath+output_filename, header=False, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
